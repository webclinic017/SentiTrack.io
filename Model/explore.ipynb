{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd028f4f8e0b771b403a9bd2068bad11876ef5f4eeb1cb023c50788a0ce2777303e",
   "display_name": "Python 3.8.5  ('.tracker': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "28f4f8e0b771b403a9bd2068bad11876ef5f4eeb1cb023c50788a0ce2777303e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"WSB_Comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neutral    596\nBear       594\nBull       591\nName: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#counts of each class\n",
    "print(data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \"\"\"\n",
    "    Applies pre-processing to text comment\n",
    "\n",
    "    Steps:\n",
    "        1. emoji to text\n",
    "        2. remove html tags\n",
    "        3. lowercase\n",
    "        4. remove punctuation \n",
    "    \"\"\"\n",
    "    #demojize emojis\n",
    "    text = emoji.demojize(text, delimiters=(\"\", \"\"))\n",
    "\n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # remove the characters [\\], ['] and [\"]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)   \n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters ='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.Series(X).apply(cleanText).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y\n",
    "X = data['Comment']\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes: 58.84%\n",
      "Logistic Regression: 63.00%\n",
      "Random Forest: 61.65%\n",
      "KNN: 47.61%\n",
      "SVM: 59.46%\n"
     ]
    }
   ],
   "source": [
    "#create pipelines and test few basic models\n",
    "classifier_names = [\"Naive Bayes\", \"Logistic Regression\", \"Random Forest\", \"KNN\", \"SVM\"]\n",
    "classifiers = [MultinomialNB(), LogisticRegression(), RandomForestClassifier(), KNeighborsClassifier(), LinearSVC()]\n",
    "zipped_clf = zip(classifier_names, classifiers)\n",
    "for n, c in zipped_clf:\n",
    "    pipeline = Pipeline([\n",
    "    ('clean', TextCleaner()),\n",
    "    ('cv', CountVectorizer(stop_words = \"english\")),\n",
    "    ('clf', c),\n",
    "    ])\n",
    "    print(n + \": {0:.2f}%\".format(np.mean(cross_val_score(pipeline, X, y, cv = 5))*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the best model\n",
    "pipeline = Pipeline([\n",
    "    ('clean', TextCleaner()),\n",
    "    ('cv', CountVectorizer(stop_words = \"english\")),\n",
    "    ('clf', LogisticRegression()),\n",
    "    ])\n",
    "pipeline.fit(X, y)\n",
    "with open(\"model.pk\", 'wb') as file:\n",
    "    pickle.dump(pipeline, file) "
   ]
  }
 ]
}